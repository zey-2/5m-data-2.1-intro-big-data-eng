Augmenting AI is the process of enhancing the capabilities of artificial intelligence systems by integrating additional data, algorithms, or technologies to improve their performance, accuracy, and adaptability.

5 V's of Big Data
- Volume
- Velocity
- Variety
- Veracity
- Value

Hadoop is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models.

Hive embeds SQL-like query language on top of Hadoop, allowing for data summarization, querying, and analysis.

Apache Kafka is very popular for real-time data processing and streaming applications. 

Flink is to process large volume of data in real-time.

Apache Spark is a unified analytics engine for big data processing, with built-in modules for streaming, SQL, machine learning and graph processing.
For example Databricks leverages Apache Spark for big data analytics.


https://www.mongodb.com/docs/manual/reference/operator/query/
